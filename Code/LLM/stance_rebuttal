from openai import OpenAI
import json
import time
import os
import re

# 🔧 **API 设置**
OPENAI_KEY = ""
OPENAI_BASE = ""
client = OpenAI(api_key=OPENAI_KEY, base_url=OPENAI_BASE)

# 📂 **文件路径**
news_file = "../../../Datasets/RAWFC/train.json"  # 原始数据
inference_file = "../../../Inference/RAWFC/No_rebuttal/train.json"#第一次LLM分析的内容
rebuttal_file = "../../SLM/only_model/Check_No_rebuttal/Stance/rebuttal_train.json"  #立场检测的结果
output_file = "../../../Inference/RAWFC/Rebuttal_stance/Rebuttal_train.json"  # 更新后的评估数据
modified_output_file = "../../../Inference/RAWFC/Rebuttal_stance/rebuttal_train_modified.json"  # 记录修改的数据


# 🎯 **统一 LLM 提示词**
def generate_prompt(news_sample, all_sentences_text):
    return f"""You are a professional rumor analysis expert. Below is a news sample and your previous analysis:

    News Sample:
    ```
    {news_sample}
    ```

    Your Previous Analysis:
    ```
    {all_sentences_text}
    ```

    However, your explanation contains inconsistencies. Some individual sentence evaluations contradict the overall judgment. Please carefully reanalyze the news according to the following structured evaluation:

    ### Evaluation Guidelines:
    1. Logical consistency: Check whether there are logical flaws or contradictions in the news narrative.
    2. Factual basis: Assess whether the claim aligns with facts using the provided explanations.
    3. Common sense comparison: Determine whether the claim aligns with general knowledge.

    ### Scoring Criteria (Total = 1.0)
    - True (completely true, no major issues): XX
    - Half (partially true, misleading elements): XX
    - False (completely false, inconsistent with facts): XX

    ### Expected Output Format
    Your answer must follow this format strictly as a plain text output:

    ```
    Score: true: 0.X, half: 0.X, false: 0.X

    Rationale: Explanation goes here...
    ```

    Ensure your response strictly follows this format and does not contain any additional text or JSON objects.
    """


# 📂 **读取 JSON 文件**
def load_json_file(file_path):
    try:
        with open(file_path, "r", encoding="utf-8") as file:
            return json.load(file)
    except (json.JSONDecodeError, FileNotFoundError):
        print(f"⚠️ Warning: Could not load {file_path}, initializing an empty dataset.")
        return {} if file_path.endswith(".json") else []


# 📌 **加载数据**
news_data = load_json_file(news_file)  # 原始新闻数据
inference_data = load_json_file(inference_file)  # 第一次LLM分析结果
rebuttal_data = load_json_file(rebuttal_file)  # 需要重新分析的 event_id
modified_data = {}  # 记录被修改的 event_id

# 🎯 **解析 event_id，确保匹配新闻数据**
news_samples = {
    str(item["event_id"]): f"Claim: {item['claim']}\nExplain: {item.get('explain', 'No_rebuttal explanation available')}"
    for item in news_data
}


# 🔍 **解析 LLM 响应**
def parse_llm_response(response):
    """
    解析 LLM 返回的文本，确保格式正确，并转换为字符串存储格式
    """
    match = re.search(
        r"Score:\s*true:\s*([\d.]+),\s*half:\s*([\d.]+),\s*false:\s*([\d.]+)\n\nRationale:\s*(.*)",
        response,
        re.DOTALL,
    )
    if match:
        true_score = float(match.group(1))
        half_score = float(match.group(2))
        false_score = float(match.group(3))
        rationale = match.group(4).strip()

        # 确保总分为 1.0
        if abs((true_score + half_score + false_score) - 1.0) < 1e-6:
            return f"Score: true: {true_score}, half: {half_score}, false: {false_score}\n\nRationale: {rationale}"

    return None


# 🔄 **遍历 `rebuttal_file` 找出需要重新分析的 event_id**
for event_id_key, event_data in rebuttal_data.items():
    event_id = str(event_id_key).replace("event_id: ", "")  # 统一 event_id 格式

    # 🏷 **获取 `all_sentences_prediction` 标签**
    all_sentences_pred = event_data.get("all_sentences_prediction", {})
    all_sentences_label = all_sentences_pred.get("predicted_label", "unknown")

    # 📊 **统计 `rationale_sentences` 中不同的标签**
    different_count = sum(
        1 for sent in event_data["rationale_sentences"] if sent["predicted_label"] != all_sentences_label)
    total_sentences = len(event_data["rationale_sentences"])

    # 🛑 **如果超过 50% 句子的标签与 `all_sentences_label` 不同，则重新分析**
    if total_sentences > 0 and (different_count / total_sentences) > 0.5:
        print(f"🔍 Event {event_id} has significant label differences. Reanalyzing...")

        # 🚀 **获取新闻样本**
        news_sample = news_samples.get(event_id, "Unknown News Sample")

        # 🚀 **构造新的 LLM prompt**
        context_messages = [
            {"role": "system", "content": generate_prompt(news_sample, all_sentences_pred.get("sentence", ""))}
        ]
        print(context_messages,"/n/n")

        retry_count = 0
        max_retries = 3

        while retry_count < max_retries:
            try:
                # 🚀 **调用 LLM 重新评估**
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=context_messages
                )

                result = response.choices[0].message.content.strip()

                # 🚀 **解析 LLM 返回结果**
                parsed_result = parse_llm_response(result)

                if parsed_result:
                    inference_data[f"item_{event_id}"] = parsed_result  # **存储字符串格式**
                    modified_data[f"item_{event_id}"] = parsed_result  # 记录被修改的数据
                    print(f"✅ Event {event_id} updated successfully.")
                    break  # 结束重试
                else:
                    print(f"❌ Invalid response format for event_id: {event_id}. Retrying...")

            except Exception as e:
                print(f"❌ API request error for event_id: {event_id}: {e}. Retrying...")

            retry_count += 1
            time.sleep(5 + retry_count * 2)  # 指数退避

# 💾 **保存数据**
with open(output_file, "w", encoding="utf-8") as file:
    json.dump(inference_data, file, ensure_ascii=False, indent=4)

with open(modified_output_file, "w", encoding="utf-8") as file:
    json.dump(modified_data, file, ensure_ascii=False, indent=4)

print(f"✅ Updated data saved to {output_file}")
print(f"✅ Modified entries saved to {modified_output_file}")
