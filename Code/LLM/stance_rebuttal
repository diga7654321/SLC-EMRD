from openai import OpenAI
import json
import time
import os
import re

# ğŸ”§ **API è®¾ç½®**
OPENAI_KEY = ""
OPENAI_BASE = ""
client = OpenAI(api_key=OPENAI_KEY, base_url=OPENAI_BASE)

# ğŸ“‚ **æ–‡ä»¶è·¯å¾„**
news_file = "../../../Datasets/RAWFC/train.json"  # åŸå§‹æ•°æ®
inference_file = "../../../Inference/RAWFC/No_rebuttal/train.json"#ç¬¬ä¸€æ¬¡LLMåˆ†æçš„å†…å®¹
rebuttal_file = "../../SLM/only_model/Check_No_rebuttal/Stance/rebuttal_train.json"  #ç«‹åœºæ£€æµ‹çš„ç»“æœ
output_file = "../../../Inference/RAWFC/Rebuttal_stance/Rebuttal_train.json"  # æ›´æ–°åçš„è¯„ä¼°æ•°æ®
modified_output_file = "../../../Inference/RAWFC/Rebuttal_stance/rebuttal_train_modified.json"  # è®°å½•ä¿®æ”¹çš„æ•°æ®


# ğŸ¯ **ç»Ÿä¸€ LLM æç¤ºè¯**
def generate_prompt(news_sample, all_sentences_text):
    return f"""You are a professional rumor analysis expert. Below is a news sample and your previous analysis:

    News Sample:
    ```
    {news_sample}
    ```

    Your Previous Analysis:
    ```
    {all_sentences_text}
    ```

    However, your explanation contains inconsistencies. Some individual sentence evaluations contradict the overall judgment. Please carefully reanalyze the news according to the following structured evaluation:

    ### Evaluation Guidelines:
    1. Logical consistency: Check whether there are logical flaws or contradictions in the news narrative.
    2. Factual basis: Assess whether the claim aligns with facts using the provided explanations.
    3. Common sense comparison: Determine whether the claim aligns with general knowledge.

    ### Scoring Criteria (Total = 1.0)
    - True (completely true, no major issues): XX
    - Half (partially true, misleading elements): XX
    - False (completely false, inconsistent with facts): XX

    ### Expected Output Format
    Your answer must follow this format strictly as a plain text output:

    ```
    Score: true: 0.X, half: 0.X, false: 0.X

    Rationale: Explanation goes here...
    ```

    Ensure your response strictly follows this format and does not contain any additional text or JSON objects.
    """


# ğŸ“‚ **è¯»å– JSON æ–‡ä»¶**
def load_json_file(file_path):
    try:
        with open(file_path, "r", encoding="utf-8") as file:
            return json.load(file)
    except (json.JSONDecodeError, FileNotFoundError):
        print(f"âš ï¸ Warning: Could not load {file_path}, initializing an empty dataset.")
        return {} if file_path.endswith(".json") else []


# ğŸ“Œ **åŠ è½½æ•°æ®**
news_data = load_json_file(news_file)  # åŸå§‹æ–°é—»æ•°æ®
inference_data = load_json_file(inference_file)  # ç¬¬ä¸€æ¬¡LLMåˆ†æç»“æœ
rebuttal_data = load_json_file(rebuttal_file)  # éœ€è¦é‡æ–°åˆ†æçš„ event_id
modified_data = {}  # è®°å½•è¢«ä¿®æ”¹çš„ event_id

# ğŸ¯ **è§£æ event_idï¼Œç¡®ä¿åŒ¹é…æ–°é—»æ•°æ®**
news_samples = {
    str(item["event_id"]): f"Claim: {item['claim']}\nExplain: {item.get('explain', 'No_rebuttal explanation available')}"
    for item in news_data
}


# ğŸ” **è§£æ LLM å“åº”**
def parse_llm_response(response):
    """
    è§£æ LLM è¿”å›çš„æ–‡æœ¬ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®ï¼Œå¹¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²å­˜å‚¨æ ¼å¼
    """
    match = re.search(
        r"Score:\s*true:\s*([\d.]+),\s*half:\s*([\d.]+),\s*false:\s*([\d.]+)\n\nRationale:\s*(.*)",
        response,
        re.DOTALL,
    )
    if match:
        true_score = float(match.group(1))
        half_score = float(match.group(2))
        false_score = float(match.group(3))
        rationale = match.group(4).strip()

        # ç¡®ä¿æ€»åˆ†ä¸º 1.0
        if abs((true_score + half_score + false_score) - 1.0) < 1e-6:
            return f"Score: true: {true_score}, half: {half_score}, false: {false_score}\n\nRationale: {rationale}"

    return None


# ğŸ”„ **éå† `rebuttal_file` æ‰¾å‡ºéœ€è¦é‡æ–°åˆ†æçš„ event_id**
for event_id_key, event_data in rebuttal_data.items():
    event_id = str(event_id_key).replace("event_id: ", "")  # ç»Ÿä¸€ event_id æ ¼å¼

    # ğŸ· **è·å– `all_sentences_prediction` æ ‡ç­¾**
    all_sentences_pred = event_data.get("all_sentences_prediction", {})
    all_sentences_label = all_sentences_pred.get("predicted_label", "unknown")

    # ğŸ“Š **ç»Ÿè®¡ `rationale_sentences` ä¸­ä¸åŒçš„æ ‡ç­¾**
    different_count = sum(
        1 for sent in event_data["rationale_sentences"] if sent["predicted_label"] != all_sentences_label)
    total_sentences = len(event_data["rationale_sentences"])

    # ğŸ›‘ **å¦‚æœè¶…è¿‡ 50% å¥å­çš„æ ‡ç­¾ä¸ `all_sentences_label` ä¸åŒï¼Œåˆ™é‡æ–°åˆ†æ**
    if total_sentences > 0 and (different_count / total_sentences) > 0.5:
        print(f"ğŸ” Event {event_id} has significant label differences. Reanalyzing...")

        # ğŸš€ **è·å–æ–°é—»æ ·æœ¬**
        news_sample = news_samples.get(event_id, "Unknown News Sample")

        # ğŸš€ **æ„é€ æ–°çš„ LLM prompt**
        context_messages = [
            {"role": "system", "content": generate_prompt(news_sample, all_sentences_pred.get("sentence", ""))}
        ]
        print(context_messages,"/n/n")

        retry_count = 0
        max_retries = 3

        while retry_count < max_retries:
            try:
                # ğŸš€ **è°ƒç”¨ LLM é‡æ–°è¯„ä¼°**
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=context_messages
                )

                result = response.choices[0].message.content.strip()

                # ğŸš€ **è§£æ LLM è¿”å›ç»“æœ**
                parsed_result = parse_llm_response(result)

                if parsed_result:
                    inference_data[f"item_{event_id}"] = parsed_result  # **å­˜å‚¨å­—ç¬¦ä¸²æ ¼å¼**
                    modified_data[f"item_{event_id}"] = parsed_result  # è®°å½•è¢«ä¿®æ”¹çš„æ•°æ®
                    print(f"âœ… Event {event_id} updated successfully.")
                    break  # ç»“æŸé‡è¯•
                else:
                    print(f"âŒ Invalid response format for event_id: {event_id}. Retrying...")

            except Exception as e:
                print(f"âŒ API request error for event_id: {event_id}: {e}. Retrying...")

            retry_count += 1
            time.sleep(5 + retry_count * 2)  # æŒ‡æ•°é€€é¿

# ğŸ’¾ **ä¿å­˜æ•°æ®**
with open(output_file, "w", encoding="utf-8") as file:
    json.dump(inference_data, file, ensure_ascii=False, indent=4)

with open(modified_output_file, "w", encoding="utf-8") as file:
    json.dump(modified_data, file, ensure_ascii=False, indent=4)

print(f"âœ… Updated data saved to {output_file}")
print(f"âœ… Modified entries saved to {modified_output_file}")
